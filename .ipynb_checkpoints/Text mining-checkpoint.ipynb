{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text mining\n",
    "\n",
    "##### text mining의 적용 분야\n",
    "1. Document classification - sentiment analysis, classification\n",
    "2. Document generation - Q&A, summarization, translation\n",
    "3. Keyword extraction - tagging/annotation\n",
    "4. Topic modeling - LSA(Latent Semantic Analysis), LDA(Latent Dirichelt Allocation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### text mining 도구 - Python\n",
    "1. NLTK - 가장 대중적인 NLP 라이브러리\n",
    "2. Scikit Learn - 머신러닝 라이브러리\n",
    "3. Genism - 텍스트 관련 도구 지원\n",
    "4. Keras - 딥러닝 위주의 라이브러리 제공\n",
    "5. Pytorch - 최근 가장 많이 사용되는 패키"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text mining 방법\n",
    "- NLP(Natural Language Processing) 기본도구\n",
    "- 목적: document, sentence 등의 word sequence를 sparse, vector로 변환\n",
    "\n",
    "##### Tokenize\n",
    "- Document를 Sentence의 집합으로 분리 / Sentence를 Word 집합으로 분리 + 의미없는 문자 등을 걸러냄\n",
    "\n",
    "##### Text Normalization\n",
    "- 동일한 의미의 단어가 다른 형태를 갖는 것을 보완\n",
    "\n",
    "##### stemming(어간 추출) - 의미가 아닌 규칙에 의한 변환 (ex. 영어의 -ing는 진행형)\n",
    "##### Lemmatization(표제어 추출) - 사전을 이용하여 단어의 원형을 추출\n",
    "##### Pos-tagging\n",
    "- 토큰화와 정규화 작업을 통해 나누어진 형태소에 대해 품사를 결정하여 할당하는 작업\n",
    "\n",
    "##### Chunking\n",
    "- 언어학적으로 말모음을 뜻함, 주어와 동사가 없는 두 단어 이상의 집합인 구(phrase)를 의미함\n",
    "\n",
    "##### BOW (Bag of Words)\n",
    "- 문서를 bag of words로 표현 -> 단어가 쓰여진 순서는 무시하며, 단어의 유/무 대신 단어가 문서에 나타난 횟수로 표현\n",
    "- Similiarity Matching or Classify로 활용할 수 있음\n",
    "\n",
    "##### TFIDF(Term Frequency - Inverse Document Frequency)\n",
    "- 단어의 count를 단어가 나타난 문서의 수로 나눠서 자주 등장하지 않는 단어의 wieght을 올림\n",
    "- tf(d,t): 문서 d에 단어 t가 나타난 횟수\n",
    "- df(t): 전체 문서 중에서 단어 t를 포함하는 문서의 수\n",
    "- idf(t): dt(t)의 역수\n",
    "\n",
    "##### BOW/TFIDF를 활용하여 Text Classification\n",
    "1. Naïve Bayes : text categorization에 가장 자주 쓰이는 method\n",
    "2. Logistic regression (Ridge regression, Lasso regression) : 분류를 위한 회귀분석\n",
    "3. Decision tree (Random Forset)\n",
    "\n",
    "##### Text mining의 문제점\n",
    "1. Curse of Dimensionality (차원의 저주)\n",
    "- 각 데이터 간의 거리가 너무 멀게 위치\n",
    "- 해결방법 : 더 많은 데이터를 사용!, 차원을 축소(dimension reduction)\n",
    "\n",
    "2. 단어 빈도의 불균형\n",
    "- Zipf's law (멱볍칙) - 소수의 데이터가 결정적인 결과에 영향을 미침\n",
    "- 해결방법 : 빈도 높은 단어 삭제, Bollean Bow 사용\n",
    "\n",
    "3. 단어가 쓰인 순서정보의 손실\n",
    "- Loss of sequence information\n",
    "- 해결방법 : n-gram, Deep learning\n",
    "\n",
    "##### 문제 해결 방법\n",
    "- Dimensionality Reduction - 차원의 축소\n",
    "- Freature selection - Manual, Regularization\n",
    "- Feature extraction - PCA(주성분 분석), LSA(SVD:특이값 분해)\n",
    "- Embedding - Word embedding, Document embedding\n",
    "- Deep learning - RBM(Restricted Boltzmann Machine), Autoencoder(RBM과 유사한 개념)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
